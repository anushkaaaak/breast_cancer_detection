{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Breast Cancer Detection using Machine Learning\n",
        "**Author:** Anushka Kandwal\n",
        "**Goal:** Classify tumors as Benign or Malignant using ML models (Logistic Regression, Random Forest, SVM).  \n",
        "\n",
        "**This project uses the Breast Cancer Wisconsin Diagnostic dataset from Kaggle. We train multiple models, evaluate them, and create an interactive dashboard for predictions.**\n",
        "\n",
        "**Tech Stack:** Python | pandas | scikit-learn | matplotlib | seaborn  \n",
        "\n",
        "**Result:** Achieved ~ 96-97 % accuracy with strong recall for Malignant class.\n",
        "\n",
        "---\n",
        "###  Getting Started in Google Colab\n",
        "1. Upload this notebook to your Google Drive.\n",
        "2. Open it with **Google Colab**.\n",
        "3. (Optional) Mount your Drive if your dataset is in Drive:\n",
        "   ```python\n",
        "   from google.colab import drive\n",
        "   drive.mount('/content/drive')\n",
        "   ```\n",
        "4. Update the CSV path if needed, then run all cells."
      ],
      "metadata": {
        "id": "laf0eOLiO0sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive"
      ],
      "metadata": {
        "id": "86hXYGcDB-Fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jfkn_Y4BunC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create Project Directory\n",
        "We first create a dedicated folder in Google Drive to store all project files, including dataset, models, and notebooks. This ensures everything is organized and easy to access."
      ],
      "metadata": {
        "id": "GStWYJ-uIaYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "project_dir = \"/content/drive/MyDrive/breast_cancer_project\"\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "print(\"Project directory created at:\", project_dir)\n"
      ],
      "metadata": {
        "id": "QIXqijYjCKJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Upload Kaggle API Key\n",
        "Used `kaggle.json` file to access Kaggle datasets directly from Colab.\n"
      ],
      "metadata": {
        "id": "DmK4qOFIIi9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here when prompted\n"
      ],
      "metadata": {
        "id": "5PHCOK0eCW_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Configure Kaggle API\n",
        "We rename and move the uploaded `kaggle.json` to the proper directory (`~/.kaggle`) so that the Kaggle API can access it.\n"
      ],
      "metadata": {
        "id": "1dDJNoUUIuNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the file and move to ~/.kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv \"kaggle (1).json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Verify setup\n",
        "!ls -l ~/.kaggle\n"
      ],
      "metadata": {
        "id": "CqjJ8RU6CcQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Download and Extract Dataset from Kaggle\n",
        "We navigate to our project directory in Google Drive, download the Breast Cancer Wisconsin dataset using the Kaggle API,\n",
        "and unzip it directly into the project folder. This ensures the dataset is stored permanently in Drive for easy access."
      ],
      "metadata": {
        "id": "Ul4dik7xI4eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd \"$project_dir\"\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d uciml/breast-cancer-wisconsin-data\n",
        "\n",
        "# Unzip it into your Drive folder\n",
        "!unzip -o breast-cancer-wisconsin-data.zip -d \"$project_dir\"\n"
      ],
      "metadata": {
        "id": "YNRVJyw1DDHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Load Dataset into Pandas\n",
        "We load the Breast Cancer dataset from our Google Drive project folder into a Pandas DataFrame.\n",
        "This allows us to perform exploratory data analysis (EDA) and preprocessing on the dataset."
      ],
      "metadata": {
        "id": "S99gLLcUJBps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = os.path.join(project_dir, \"data.csv\")\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Dataset loaded successfully from Drive!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "j2YID1jRDGkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Explore Dataset Structure\n",
        "We check the dataset shape, column names, and general information to understand the data types,\n"
      ],
      "metadata": {
        "id": "SWvjM-JbJNXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumn names:\\n\", df.columns.tolist())\n",
        "\n",
        "\n",
        "print(\"\\nData info:\")\n",
        "df.info()\n",
        "\n",
        "# Quick look at first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Si7Y8kloDOYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Check for Missing Values and Duplicates\n",
        " verifing the  data quality by checking for missing values in each column and identifying duplicate rows.\n",
        "This helps ensure that our dataset is clean before preprocessing and model training."
      ],
      "metadata": {
        "id": "460DgyJiJWxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Check duplicates\n",
        "print(\"\\nDuplicates:\", df.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "W5wrupIaDTy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Dataset Distribution\n",
        "Dataset is checked to see the number of Benign (B) and Malignant (M) cases.\n",
        "This helps to ensure if the dataset is balanced or imbalanced."
      ],
      "metadata": {
        "id": "4cR94eHOJiV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(df['diagnosis'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x='diagnosis', data=df, palette='Set2')\n",
        "plt.title(\"Class Distribution (Benign vs Malignant)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TbEo0LMeDYEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9 : Data Cleaning: Removing Irrelevant Columns"
      ],
      "metadata": {
        "id": "-1aGWH30krr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id'], inplace=True)\n",
        "if 'Unnamed: 32' in df.columns:\n",
        "    df.drop(columns=['Unnamed: 32'], inplace=True)\n",
        "\n",
        "print(\"Remaining columns:\", len(df.columns))\n"
      ],
      "metadata": {
        "id": "v8ZDnMEeDijX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "df['diagnosis'].value_counts()\n"
      ],
      "metadata": {
        "id": "JOYbcf9aDnFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Correlation Heatmap with Target Variable (`diagnosis`)"
      ],
      "metadata": {
        "id": "x09RanQuk7HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "corr = df.corr(numeric_only=True)\n",
        "sns.heatmap(corr[['diagnosis']].sort_values(by='diagnosis', ascending=False),\n",
        "            annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation with Diagnosis\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wudka715DqYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: Train-Test Split and Feature Scaling"
      ],
      "metadata": {
        "id": "gWT73EcKlDfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape)\n",
        "print(\"Test size:\", X_test.shape)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data scaled successfully.\")\n"
      ],
      "metadata": {
        "id": "Zlv4AJ6ODvSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries"
      ],
      "metadata": {
        "id": "U7t-qrARlFaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "zquBi8fSD1qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Logistic Regression â€” Training and Evaluation"
      ],
      "metadata": {
        "id": "i3HzmX4AlSbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Logistic Regression Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eR3LqqB2D4t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Learning with Random Forest for Breast Cancer Classification"
      ],
      "metadata": {
        "id": "pg-eG3qJlZgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y-eOtT73D8RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine (SVM) Classification with Performance Evaluation and Visualization"
      ],
      "metadata": {
        "id": "j7fn99NpmA4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_svm)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Oranges\")\n",
        "plt.title(\"SVM Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7u5bp9sAD_nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC Curve Comparison for Logistic Regression, Random Forest, and SVM Models"
      ],
      "metadata": {
        "id": "AYqNZ_2dmQSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "models = {'Logistic Regression': lr, 'Random Forest': rf, 'SVM': svm}\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_prob = model.predict_proba(X_test_scaled)[:,1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mT_D3RylECkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Model Saving"
      ],
      "metadata": {
        "id": "drdItDTOmb83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q joblib\n",
        "\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "43rxL0ddEImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting and Saving the Best Model (Random Forest)"
      ],
      "metadata": {
        "id": "IG-X3t83mjmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = rf  # Random Forest\n"
      ],
      "metadata": {
        "id": "uZxvhiIoEbDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(project_dir, \"best_model.pkl\")\n",
        "scaler_path = os.path.join(project_dir, \"scaler.pkl\")\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(best_model, model_path)\n",
        "\n",
        "# Save the scaler used for feature scaling\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "print(\"Model saved at:\", model_path)\n",
        "print(\"Scaler saved at:\", scaler_path)\n"
      ],
      "metadata": {
        "id": "GItsZGo1EdsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving Trained Model and Scaler for Deployment Using Joblib"
      ],
      "metadata": {
        "id": "Z4qCjd1UmtF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model & scaler from Drive\n",
        "loaded_model = joblib.load(model_path)\n",
        "loaded_scaler = joblib.load(scaler_path)\n",
        "\n",
        "# Example: predict on first 5 test samples\n",
        "X_sample = X_test.iloc[:5]\n",
        "X_sample_scaled = loaded_scaler.transform(X_sample)\n",
        "preds = loaded_model.predict(X_sample_scaled)\n",
        "print(\"Predictions (0=Benign, 1=Malignant):\", preds)\n"
      ],
      "metadata": {
        "id": "ODuK7PyrEgva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breast Cancer Prediction Function Using Trained Random Forest Model"
      ],
      "metadata": {
        "id": "YQLasIUGm0Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_breast_cancer(model, scaler, input_data):\n",
        "    \"\"\"\n",
        "    Predict breast cancer based on input features.\n",
        "\n",
        "    Parameters:\n",
        "    - model: trained ML model (Random Forest)\n",
        "    - scaler: fitted StandardScaler\n",
        "    - input_data: pandas DataFrame with the same features as training data\n",
        "\n",
        "    Returns:\n",
        "    - predictions: list of 'Benign' or 'Malignant'\n",
        "    \"\"\"\n",
        "    # Scale features\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Predict\n",
        "    pred_numeric = model.predict(input_scaled)\n",
        "\n",
        "    # Convert to human-readable\n",
        "    pred_labels = ['Benign' if x==0 else 'Malignant' for x in pred_numeric]\n",
        "\n",
        "    return pred_labels\n"
      ],
      "metadata": {
        "id": "B_IU6PscErOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sample Predictions and Comparison with Actual Labels"
      ],
      "metadata": {
        "id": "cLJ1LjNwm6lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select first 5 test samples\n",
        "X_sample = X_test.iloc[:5]\n",
        "\n",
        "# Make predictions\n",
        "predictions = predict_breast_cancer(loaded_model, loaded_scaler, X_sample)\n",
        "print(\"Predictions:\", predictions)\n",
        "\n",
        "# Compare with actual labels\n",
        "print(\"Actual:\", ['Malignant' if x==1 else 'Benign' for x in y_test.iloc[:5]])\n"
      ],
      "metadata": {
        "id": "EFWFelAjEt1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Widget Setup for User Input in Breast Cancer Prediction"
      ],
      "metadata": {
        "id": "bGog3am8nBh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "# Feature names in correct order\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "# Pre-fill with mean values from training data\n",
        "feature_means = X_train.mean()\n"
      ],
      "metadata": {
        "id": "O6Nzw1BsE6Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Scrollable Input Form for Interactive Feature Entry"
      ],
      "metadata": {
        "id": "CQ1-GqewnH3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold widgets\n",
        "feature_widgets = {}\n",
        "\n",
        "# VBox children list\n",
        "widget_list = []\n",
        "\n",
        "for f in feature_names:\n",
        "    w = widgets.FloatText(\n",
        "        value=float(feature_means[f]),\n",
        "        description=f,\n",
        "        step=0.01,\n",
        "        layout=widgets.Layout(width='350px')\n",
        "    )\n",
        "    feature_widgets[f] = w\n",
        "    widget_list.append(w)\n",
        "\n",
        "# Make scrollable container\n",
        "input_form = widgets.VBox(widget_list, layout=widgets.Layout(\n",
        "    height='500px', overflow_y='scroll', border='1px solid gray', padding='10px'\n",
        "))\n",
        "display(input_form)\n"
      ],
      "metadata": {
        "id": "jwHs88ZuFANZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Breast Cancer Prediction with Real-Time Confidence Output"
      ],
      "metadata": {
        "id": "8rNLIIZqnQId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_button = widgets.Button(description=\"Predict Breast Cancer\", button_style='success')\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_predict_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        # Read input values in correct order\n",
        "        input_data = {f: [feature_widgets[f].value] for f in feature_names}\n",
        "        input_df = pd.DataFrame(input_data)\n",
        "\n",
        "        # Predict\n",
        "        pred_label = predict_breast_cancer(loaded_model, loaded_scaler, input_df)[0]\n",
        "        prob = loaded_model.predict_proba(loaded_scaler.transform(input_df))[0][1]\n",
        "\n",
        "        print(f\"Prediction: {pred_label}\")\n",
        "        print(f\"Confidence (Malignant probability): {prob*100:.2f}%\")\n",
        "\n",
        "predict_button.on_click(on_predict_clicked)\n",
        "display(predict_button, output)\n",
        "\n"
      ],
      "metadata": {
        "id": "uvTt3T5pFGxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}